{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ee09d1",
   "metadata": {},
   "source": [
    "# Importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Importing libraries...\")\n",
    "import shutil\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import Image, display, Markdown\n",
    "import argparse\n",
    "print(\"Libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec617ba-f24f-47d3-b80f-263e33ee8356",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "NVD_ROOT            = Path('../nvd/nvd_dataset_full')  # must have images/{train,val,test}, labels/{train,val,test}\n",
    "PCNVD_LABEL_DIR     = Path('PCNVD/Labels')\n",
    "PCNVD_IMAGE_DIR     = Path('PCNVD/Images_BIGBOY')\n",
    "OUT_ROOT            = Path('combined_yolo_dataset_full_no_aug')\n",
    "CLASS_NAMES         = ['car']\n",
    "MAX_BACKGROUND_RATIO = 0.01  # Maximum 20% of train images can be background-only\n",
    "\n",
    "# â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def copy_split_from_nvd():\n",
    "    \"\"\"Copy pre-split NVD dataset to output directory, and count background-only train images.\"\"\"\n",
    "    nvd_background_count = 0\n",
    "    nvd_train_count = 0\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        img_dir = NVD_ROOT / 'images' / split\n",
    "        lbl_dir = NVD_ROOT / 'labels' / split\n",
    "\n",
    "        for sub in [f'images/{split}', f'labels/{split}']:\n",
    "            (OUT_ROOT / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        img_files = sorted(img_dir.glob('*.[jp][pn]g'))\n",
    "        for img_path in img_files:\n",
    "            stem = img_path.stem\n",
    "            lbl_path = lbl_dir / f\"{stem}.txt\"\n",
    "            dst_img = OUT_ROOT / f'images/{split}/{img_path.name}'\n",
    "            dst_lbl = OUT_ROOT / f'labels/{split}/{stem}.txt'\n",
    "\n",
    "            shutil.copy(img_path, dst_img)\n",
    "            if lbl_path.exists():\n",
    "                shutil.copy(lbl_path, dst_lbl)\n",
    "                is_empty = lbl_path.stat().st_size == 0\n",
    "            else:\n",
    "                dst_lbl.write_text(\"\")\n",
    "                is_empty = True\n",
    "\n",
    "            if split == 'train':\n",
    "                nvd_train_count += 1\n",
    "                if is_empty:\n",
    "                    nvd_background_count += 1\n",
    "\n",
    "    return nvd_train_count, nvd_background_count\n",
    "\n",
    "def augment_train_with_pcnvd(current_total, current_background):\n",
    "    \"\"\"Augment training set with PCNVD images and labels, limiting total background ratio.\"\"\"\n",
    "    pcnvd_imgs = sorted([p for p in PCNVD_IMAGE_DIR.iterdir() if p.suffix.lower() in ['.jpg', '.png']])\n",
    "    random.shuffle(pcnvd_imgs)\n",
    "\n",
    "    total = current_total\n",
    "    background = current_background\n",
    "    added = 0\n",
    "\n",
    "    for img_path in pcnvd_imgs:\n",
    "        stem = img_path.stem\n",
    "        lbl_path = PCNVD_LABEL_DIR / f\"{stem}.txt\"\n",
    "        dst_img = OUT_ROOT / f\"images/train/{img_path.name}\"\n",
    "        dst_lbl = OUT_ROOT / f\"labels/train/{stem}.txt\"\n",
    "\n",
    "        if dst_img.exists():\n",
    "            # Allow duplicates by suffix\n",
    "            i = 1\n",
    "            while dst_img.exists():\n",
    "                dst_img = OUT_ROOT / f\"images/train/{stem}_{i}{img_path.suffix}\"\n",
    "                dst_lbl = OUT_ROOT / f\"labels/train/{stem}_{i}.txt\"\n",
    "                i += 1\n",
    "\n",
    "        if lbl_path.exists() and lbl_path.stat().st_size > 0:\n",
    "            shutil.copy(img_path, dst_img)\n",
    "            shutil.copy(lbl_path, dst_lbl)\n",
    "            total += 1\n",
    "            added += 1\n",
    "        else:\n",
    "            # Check if adding this would exceed 20% background limit\n",
    "            if (background + 1) / (total + 1) <= MAX_BACKGROUND_RATIO:\n",
    "                shutil.copy(img_path, dst_img)\n",
    "                dst_lbl.write_text(\"\")\n",
    "                background += 1\n",
    "                total += 1\n",
    "                added += 1\n",
    "            # else: skip this background image\n",
    "\n",
    "    print(f\"â• Augmented {added} PCNVD images into training set.\")\n",
    "    print(f\"ğŸ“Š Final train set: {total} images, {background} background-only ({(background / total):.2%})\")\n",
    "\n",
    "def write_data_yaml():\n",
    "    data = {\n",
    "        'path': str(OUT_ROOT.resolve()),\n",
    "        'train': 'images/train',\n",
    "        'val':   'images/val',\n",
    "        'test':  'images/test',\n",
    "        'names': CLASS_NAMES\n",
    "    }\n",
    "    with open(OUT_ROOT / 'data.yaml', 'w') as f:\n",
    "        yaml.dump(data, f, sort_keys=False)\n",
    "\n",
    "def prepare_dataset():\n",
    "    if OUT_ROOT.exists():\n",
    "        shutil.rmtree(OUT_ROOT)\n",
    "    print(\"ğŸ“¦ Copying main dataset from NVD...\")\n",
    "    nvd_total, nvd_background = copy_split_from_nvd()\n",
    "    print(f\"ğŸ“Š NVD train images: {nvd_total}, background-only: {nvd_background} ({(nvd_background / nvd_total):.2%})\")\n",
    "    # print(\"ğŸ” Augmenting training set with PCNVD (enforcing 1% max background)...\")\n",
    "    # augment_train_with_pcnvd(nvd_total, nvd_background)\n",
    "    write_data_yaml()\n",
    "    print(f\"âœ… Dataset prepared under {OUT_ROOT}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(42)\n",
    "    prepare_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8742f51d",
   "metadata": {},
   "source": [
    "# Hyperparameter Tune\n",
    "* data_root_path\n",
    "* out_yaml_name\n",
    "* trials\n",
    "* epochs\n",
    "* imgsz\n",
    "* batch\n",
    "* freeze_backbone\n",
    "* patience\n",
    "* seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tune_hyperparameters(\n",
    "    data_root_path,\n",
    "    out_yaml_name,\n",
    "    trials=20,\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    freeze_backbone=False,\n",
    "    patience=10,\n",
    "    seed=42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run hyperparameter tuning (YOLO .tune) against a dataset and save the best hyp yaml.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- Seeding for reproducibility ----\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    data_root = Path(data_root_path)\n",
    "    if not data_root.exists():\n",
    "        raise FileNotFoundError(f\"Dataset root not found: {data_root}\")\n",
    "\n",
    "    OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # write a temporary data.yaml pointing to the provided dataset root\n",
    "    temp_data_yaml = OUT_ROOT / f\"data_for_tune_{int(time.time())}.yaml\"\n",
    "    data = {\n",
    "        \"path\": str(data_root.resolve()),\n",
    "        \"train\": \"images/train\",\n",
    "        \"val\": \"images/val\",\n",
    "        \"test\": \"images/test\",\n",
    "        \"names\": CLASS_NAMES,\n",
    "    }\n",
    "    with open(temp_data_yaml, \"w\") as f:\n",
    "        yaml.dump(data, f, sort_keys=False)\n",
    "\n",
    "    # run tuning\n",
    "    model = YOLO(\"yolov8m.pt\")\n",
    "    tune_name = f\"hp_tune_{temp_data_yaml.stem}\"\n",
    "\n",
    "    # map bool -> freeze layers (adjust number if you want deeper freeze)\n",
    "    freeze = 10 if freeze_backbone else 0\n",
    "\n",
    "    model.tune(\n",
    "        data=str(temp_data_yaml),\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,\n",
    "        name=tune_name,\n",
    "        freeze=freeze_backbone,\n",
    "        optimizer='AdamW',\n",
    "        augment=True,\n",
    "        patience=patience,\n",
    "        iterations=trials,\n",
    "    )\n",
    "\n",
    "    # find the most recent hyperparameter file produced under runs/\n",
    "    candidates = []\n",
    "    # Newer Ultralytics: best_hyperparameters.yaml\n",
    "    candidates.extend(Path(\"runs\").rglob(\"best_hyperparameters.yaml\"))\n",
    "    # Older style (or custom): hyp.yaml\n",
    "    candidates.extend(Path(\"runs\").rglob(\"hyp.yaml\"))\n",
    "\n",
    "    if not candidates:\n",
    "        print(\n",
    "            \"No best_hyperparameters.yaml or hyp.yaml found under runs/. \"\n",
    "            \"Tuning may have failed or the output filename changed.\"\n",
    "        )\n",
    "        try:\n",
    "            temp_data_yaml.unlink()\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "    candidates.sort(key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    best_hyp = candidates[0]\n",
    "\n",
    "    dest = OUT_ROOT / out_yaml_name\n",
    "    shutil.copy(best_hyp, dest)\n",
    "    print(f\"Tuned hyperparameters copied to: {dest}\")\n",
    "\n",
    "    # clean up temporary data yaml\n",
    "    try:\n",
    "        temp_data_yaml.unlink()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return dest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de12ef78-e3c6-4e1d-acd4-ab6a8bb57f3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Defaults (can still be overridden via CLI)\n",
    "OUT_ROOT    = Path('combined_yolo_dataset_full_no_aug')\n",
    "EXPERIMENT  = 'yolov8m_big_NVD_augment_less_background'\n",
    "EPOCHS      = 200\n",
    "IMGSZ       = 640\n",
    "BATCH       = 16\n",
    "FREEZE_BACKBONE = False\n",
    "PATIENCE    = 10\n",
    "CONF_THRESH = 0.001\n",
    "IOU_THRESH  = 0.50\n",
    "\n",
    "\n",
    "def train(\n",
    "    data_root: Path,\n",
    "    experiment_name: str,\n",
    "    hyp_path: Path | None = None,\n",
    "    epochs: int = EPOCHS,\n",
    "    imgsz: int = IMGSZ,\n",
    "    batch: int = BATCH,\n",
    "    freeze_backbone: bool = FREEZE_BACKBONE,\n",
    "    patience: int = PATIENCE,\n",
    "):\n",
    "    \"\"\"Train YOLOv8 on a given dataset + optional hyp.yaml.\"\"\"\n",
    "    model = YOLO('yolov8m.pt')\n",
    "\n",
    "    # If no hyp_path provided, fall back to your manual dict\n",
    "    if hyp_path is None:\n",
    "        hyp = {\n",
    "            'lr0': 0.003,\n",
    "            'lrf': 0.1,\n",
    "            'momentum': 0.937,\n",
    "            'weight_decay': 0.0005,\n",
    "            'warmup_epochs': 3.0,\n",
    "            'warmup_momentum': 0.8,\n",
    "            'warmup_bias_lr': 0.1,\n",
    "            'box': 0.5,\n",
    "            'cls': 0.05,\n",
    "            'dfl': 1.5,\n",
    "            'label_smoothing': 0.0,\n",
    "            'nbs': 64,\n",
    "            'hsv_h': 0.015,\n",
    "            'hsv_s': 0.7,\n",
    "            'hsv_v': 0.4,\n",
    "            'degrees': 5.0,\n",
    "            'translate': 0.1,\n",
    "            'scale': 0.4,\n",
    "            'shear': 2.0,\n",
    "            'perspective': 0.001,\n",
    "            'flipud': 0.0,\n",
    "            'fliplr': 0.5,\n",
    "            'mosaic': 1.0,\n",
    "            'mixup': 0.2,\n",
    "            'copy_paste': 0.1,\n",
    "        }\n",
    "\n",
    "        hyp_path = data_root / 'hyp.yaml'\n",
    "        hyp_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(hyp_path, 'w') as f:\n",
    "            yaml.dump(hyp, f)\n",
    "\n",
    "    # Train\n",
    "    model.train(\n",
    "        data=str(data_root / \"data.yaml\"),\n",
    "        epochs=epochs,\n",
    "        imgsz=imgsz,\n",
    "        batch=batch,\n",
    "        name=experiment_name,   # â† training name!\n",
    "        optimizer=\"AdamW\",\n",
    "        freeze=FREEZE_BACKBONE,\n",
    "        augment=True,\n",
    "        patience=PATIENCE,\n",
    "        cfg=str(hyp_path),\n",
    "    )\n",
    "\n",
    "    # Path to YOLOâ€™s saved best model\n",
    "    best_weight_src = (\n",
    "        Path(\"runs\") / \"train\" / experiment_name / \"weights\" / \"best.pt\"\n",
    "    )\n",
    "\n",
    "    # Path where YOU want the best model saved\n",
    "    best_weight_dst = Path(\"models\") / f\"{experiment_name}_best.pt\"\n",
    "    best_weight_dst.parent.mkdir(exist_ok=True)\n",
    "\n",
    "    if not best_weight_src.exists():\n",
    "        raise FileNotFoundError(f\"Trained weights not found: {best_weight_src}\")\n",
    "\n",
    "    try:\n",
    "        shutil.copy(best_weight_src, best_weight_dst)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to copy best weights from {best_weight_src} to {best_weight_dst}: {e}\") from e\n",
    "\n",
    "    print(f\"\\nBest model saved as: {best_weight_dst}\")\n",
    "\n",
    "\n",
    "def infer(\n",
    "    data_root: Path,\n",
    "    experiment_name: str,\n",
    "    imgsz: int = IMGSZ,\n",
    "    conf: float = CONF_THRESH,\n",
    "    iou: float = IOU_THRESH,\n",
    "):\n",
    "    \"\"\"Run inference using the trained weights from a given experiment.\"\"\"\n",
    "    weights = Path(\"models\") / f\"{experiment_name}_best.pt\"\n",
    "    if not weights.exists():\n",
    "        sys.exit(f\"ERROR: model not found: {weights}\")\n",
    "\n",
    "    model = YOLO(str(weights))\n",
    "\n",
    "\n",
    "    model = YOLO(str(weights))\n",
    "    results = model.predict(\n",
    "        source=str(data_root / 'images' / 'val'),\n",
    "        imgsz=imgsz,\n",
    "        conf=conf,\n",
    "        iou=iou,\n",
    "        save=True,\n",
    "    )\n",
    "\n",
    "    print(\"\\nInference Summary:\")\n",
    "    for r in results:\n",
    "        confs = r.boxes.conf.cpu().numpy() if r.boxes.conf.nelement() else []\n",
    "        print(f\"{r.orig_shape} â†’ {len(confs)} detections, scores: {confs}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Train and infer YOLOv8 on a dataset.\")\n",
    "    parser.add_argument('--data_root', type=Path, default=OUT_ROOT, help='Path to dataset root.')\n",
    "    parser.add_argument('--experiment', type=str, default=EXPERIMENT, help='Experiment name for outputs.')\n",
    "    parser.add_argument('--hyp_path', type=Path, default=None, help='Path to hyperparameter YAML file.')\n",
    "    parser.add_argument('--epochs', type=int, default=EPOCHS, help='Number of training epochs.')\n",
    "    parser.add_argument('--imgsz', type=int, default=IMGSZ, help='Image size for training and inference.')\n",
    "    parser.add_argument('--batch', type=int, default=BATCH, help='Batch size for training.')\n",
    "    parser.add_argument('--freeze_backbone', action='store_true', help='Whether to freeze backbone during training.')\n",
    "    parser.add_argument('--patience', type=int, default=PATIENCE, help='Early stopping patience.')\n",
    "    parser.add_argument('--conf_thresh', type=float, default=CONF_THRESH, help='Confidence threshold for inference.')\n",
    "    parser.add_argument('--iou_thresh', type=float, default=IOU_THRESH, help='IOU threshold for inference.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"ğŸš€ Starting training...\")\n",
    "    train(\n",
    "        data_root=args.data_root,\n",
    "        experiment_name=args.experiment,\n",
    "        hyp_path=args.hyp_path,\n",
    "        epochs=args.epochs,\n",
    "        imgsz=args.imgsz,\n",
    "        batch=args.batch,\n",
    "        freeze_backbone=args.freeze_backbone,\n",
    "        patience=args.patience,\n",
    "    )\n",
    "\n",
    "    print(\"ğŸ” Starting inference...\")\n",
    "    infer(\n",
    "        data_root=args.data_root,\n",
    "        experiment_name=args.experiment,\n",
    "        imgsz=args.imgsz,\n",
    "        conf=args.conf_thresh,\n",
    "        iou=args.iou_thresh,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f9b9a-5b53-4797-a744-d9a38869ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "\n",
    "# â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "WEIGHTS       = \"runs/detect/yolov8m_big_NVD_augment_less_background_best/weights/best.pt\"\n",
    "DATA_YAML     = \"combined_yolo_dataset_full/data.yaml\"\n",
    "\n",
    "IMG_ROOT      = Path(\"../nvd/nvd_dataset_full/images/test\")\n",
    "LABEL_DIR     = Path(\"../nvd/nvd_dataset_full/labels/test\")\n",
    "OUTPUT_DIR    = Path(\"annotated_tests\")\n",
    "\n",
    "CONF_THRESH   = 0.5\n",
    "IOU_THRESH    = 0.5   # currently unused, but kept for future TP/FP analysis\n",
    "\n",
    "CLASS_ID      = 0     # class index, e.g. 'car'\n",
    "NUM_VIS       = 30    # how many images to visualize\n",
    "NUM_EVAL_RUNS = 5     # how many times to run model.val() and average metrics\n",
    "\n",
    "RANDOM_SEED   = 15\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "\n",
    "# â”€â”€â”€ HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def get_gt_boxes(label_file: Path, class_id: int):\n",
    "    \"\"\"Read YOLO-format GT boxes for a specific class from a label file.\"\"\"\n",
    "    boxes = []\n",
    "    if not label_file.exists():\n",
    "        return boxes\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "            if int(parts[0]) == class_id:\n",
    "                _, x_center, y_center, width, height = map(float, parts)\n",
    "                boxes.append((x_center, y_center, width, height))\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def yolo_to_xyxy(box, img_w: int, img_h: int):\n",
    "    \"\"\"Convert normalized YOLO box (xc, yc, w, h) to pixel [x1, y1, x2, y2].\"\"\"\n",
    "    x_c, y_c, w, h = box\n",
    "    x1 = int((x_c - w / 2) * img_w)\n",
    "    y1 = int((y_c - h / 2) * img_h)\n",
    "    x2 = int((x_c + w / 2) * img_w)\n",
    "    y2 = int((y_c + h / 2) * img_h)\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "\n",
    "def find_valid_images(img_root: Path, label_dir: Path, class_id: int):\n",
    "    \"\"\"\n",
    "    Return all images that have at least one GT box of CLASS_ID,\n",
    "    and a cache of GT boxes keyed by image path.\n",
    "    \"\"\"\n",
    "    valid_images = []\n",
    "    gt_cache = {}\n",
    "\n",
    "    for img_path in sorted(img_root.glob(\"*.*\")):\n",
    "        if img_path.suffix.lower() not in (\".jpg\", \".jpeg\", \".png\"):\n",
    "            continue\n",
    "        lbl_path = label_dir / f\"{img_path.stem}.txt\"\n",
    "        gt_boxes = get_gt_boxes(lbl_path, class_id)\n",
    "        if gt_boxes:\n",
    "            valid_images.append(img_path)\n",
    "            gt_cache[img_path] = gt_boxes\n",
    "\n",
    "    return valid_images, gt_cache\n",
    "\n",
    "\n",
    "def evaluate_multiple_runs(model, data_yaml: str, class_id: int,\n",
    "                           conf_thresh: float, num_runs: int):\n",
    "    \"\"\"\n",
    "    Run model.val() num_runs times and return:\n",
    "      - avg metrics (dict)\n",
    "      - std metrics (dict)\n",
    "      - list of metrics per run\n",
    "    \"\"\"\n",
    "    metrics_list = []\n",
    "\n",
    "    for i in range(num_runs):\n",
    "        print(f\"\\nâ–¶ Evaluation run {i + 1}/{num_runs} ...\")\n",
    "        results = model.val(\n",
    "            data=data_yaml,\n",
    "            conf=conf_thresh,\n",
    "            split=\"test\",\n",
    "            verbose=False,\n",
    "        )\n",
    "        m = results.box\n",
    "\n",
    "        precision, recall, ap50, ap = m.class_result(class_id)\n",
    "        metrics = {\n",
    "            \"precision\": precision,\n",
    "            \"recall\":    recall,\n",
    "            \"ap50\":      ap50,\n",
    "            \"ap\":        ap,\n",
    "            \"map50\":     m.map50,\n",
    "            \"map\":       m.map,\n",
    "        }\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    # average and std over runs\n",
    "    keys = metrics_list[0].keys()\n",
    "    avg = {k: float(np.mean([m[k] for m in metrics_list])) for k in keys}\n",
    "    std = {k: float(np.std([m[k] for m in metrics_list])) for k in keys}\n",
    "\n",
    "    print(f\"\\nğŸ” Averaged Evaluation Metrics over {num_runs} runs:\")\n",
    "    print(f\"ğŸ“ˆ Precision       : {avg['precision']:.4f} Â± {std['precision']:.4f}\")\n",
    "    print(f\"ğŸ“‰ Recall          : {avg['recall']:.4f} Â± {std['recall']:.4f}\")\n",
    "    print(f\"ğŸ AP@0.5          : {avg['ap50']:.4f} Â± {std['ap50']:.4f}\")\n",
    "    print(f\"ğŸ“Š AP@0.5:0.95     : {avg['ap']:.4f} Â± {std['ap']:.4f}\")\n",
    "    print(f\"ğŸ¯ mAP@0.5 (mean)  : {avg['map50']:.4f} Â± {std['map50']:.4f}\")\n",
    "    print(f\"ğŸ¯ mAP@0.5:0.95    : {avg['map']:.4f} Â± {std['map']:.4f}\")\n",
    "\n",
    "    return avg, std, metrics_list\n",
    "\n",
    "\n",
    "def visualize_samples(model,\n",
    "                      gt_cache: dict,\n",
    "                      class_id: int,\n",
    "                      num_vis: int,\n",
    "                      conf_thresh: float,\n",
    "                      output_dir: Path):\n",
    "    \"\"\"Select images, run batched prediction, and save/show annotated samples.\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    valid_images = list(gt_cache.keys())\n",
    "    if len(valid_images) == 0:\n",
    "        print(\"No valid images with GT for this class.\")\n",
    "        return\n",
    "\n",
    "    if len(valid_images) < num_vis:\n",
    "        num_vis = len(valid_images)\n",
    "\n",
    "    selected_images = random.sample(valid_images, num_vis)\n",
    "\n",
    "    # Batch prediction for speed\n",
    "    preds = model.predict(\n",
    "        source=[str(p) for p in selected_images],\n",
    "        conf=conf_thresh,\n",
    "        save=False,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    for idx, (img_path, res) in enumerate(zip(selected_images, preds), 1):\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            print(f\"Warning: could not read image {img_path}\")\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # Ground truth boxes (cached)\n",
    "        gt_boxes_yolo = gt_cache[img_path]\n",
    "        gt_boxes = [yolo_to_xyxy(box, w, h) for box in gt_boxes_yolo]\n",
    "\n",
    "        # Draw predictions (green) for this class\n",
    "        for box, cls_id, conf in zip(res.boxes.xyxy, res.boxes.cls, res.boxes.conf):\n",
    "            if int(cls_id) != class_id:\n",
    "                continue\n",
    "            x1, y1, x2, y2 = map(int, box.cpu().numpy())\n",
    "            label = f\"{model.names[class_id]} {conf:.2f}\"\n",
    "            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            ts = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
    "            cv2.rectangle(img_rgb, (x1, y1 - ts[1] - 4),\n",
    "                          (x1 + ts[0], y1), (0, 255, 0), -1)\n",
    "            cv2.putText(img_rgb, label, (x1, y1 - 2),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "        # Draw GT boxes (blue)\n",
    "        for gb in gt_boxes:\n",
    "            x1, y1, x2, y2 = gb\n",
    "            cv2.rectangle(img_rgb, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(img_rgb, \"GT\", (x1, y1 - 6),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "        out_path = output_dir / f\"sample_{idx:02d}_{img_path.name}\"\n",
    "        cv2.imwrite(str(out_path), cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "        display(Markdown(f\"### {idx}. {img_path.name}\"))\n",
    "        display(Image(filename=str(out_path)))\n",
    "\n",
    "\n",
    "# â”€â”€â”€ MAIN FLOW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load model once\n",
    "    model = YOLO(WEIGHTS)\n",
    "\n",
    "    # 2) Run evaluation multiple times and average the metrics\n",
    "    avg_metrics, std_metrics, all_runs = evaluate_multiple_runs(\n",
    "        model=model,\n",
    "        data_yaml=DATA_YAML,\n",
    "        class_id=CLASS_ID,\n",
    "        conf_thresh=CONF_THRESH,\n",
    "        num_runs=NUM_EVAL_RUNS,\n",
    "    )\n",
    "\n",
    "    # 3) Find valid images (with GT for CLASS_ID) and cache GT boxes\n",
    "    valid_images, gt_cache = find_valid_images(IMG_ROOT, LABEL_DIR, CLASS_ID)\n",
    "    print(f\"\\nFound {len(valid_images)} images with GT for class {CLASS_ID}.\")\n",
    "\n",
    "    # 4) Visualize NUM_VIS sample images\n",
    "    visualize_samples(\n",
    "        model=model,\n",
    "        gt_cache=gt_cache,\n",
    "        class_id=CLASS_ID,\n",
    "        num_vis=NUM_VIS,\n",
    "        conf_thresh=CONF_THRESH,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2287c568-e2a8-4302-a6b7-933bcda1a907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
